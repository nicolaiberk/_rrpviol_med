---
title: "Exploration media reactions"
author: "Nicolai Berk"
date: "28 6 2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, warning = F, message = F, cache = F)

library(here)
library(tidyverse)
library(data.table)
library(glue)
library(lubridate)
library(vars)
library(tseries)
library(dplyr)

```

## Supervised estimates of newspaper articles

This document will explore the estimates of newspaper articles generated by a supervised model. For each article, a buest guess (True/False) of whether the article is about immigration was produced, together with a probability of how likely the article is about immigration. This gives both a binary and a continuous dependent. 


```{r load, include = F}

dta <- fread(here('_dt/_mig_estimates/BERT_estimates_cleaned.csv'), header = T)
dta <- 
  dta[2:nrow(dta),] %>%  # get rid of duplicate title row
  dplyr::select(!V1) %>% # get rid of index
  mutate(
    est = as.numeric(est),
    label = as.logical(label),
    date = as.Date(date) # this does not work, get code from other files
  ) %>% 
  filter(!is.na(est))

```



## Summary statistics

### overview of dataset

```{r summary}

summary(dta)

dta <- dta %>% filter(date <= as.Date('2019-12-31')) # equal end of data for all papers

```

### Share of positives and histogram of probability

```{r hist}
print(paste('Share of migration articles:', round(sum(dta$mig_pred)/nrow(dta), 3)))

round(prop.table(table(dta$paper, dta$mig_pred), margin = 1), 3)

hist(dta$mig_proba, main = "Estimated probability an article is about migration")

```

## articles over time

```{r overtime}
dta %>% 
  filter(mig_pred == 1 & (date > lubridate::ym('2013-01'))) %>%
  ggplot() +
  ggridges::geom_density_ridges(aes(x = date, y = paper)) +
  ggtitle('Distribution of migration-related articles')

dta %>% 
  filter((date > lubridate::ym('2013-01'))) %>%
  ggplot() +
  ggridges::geom_density_ridges(aes(x = date, y = paper)) +
  ggtitle('Distribution of all articles')



# dta %>% 
#   filter((date > lubridate::ym('2013-01'))) %>%
#   ggplot(aes(x = date, y = mig_proba)) +
#   geom_smooth(aes(col = paper)) +
#   geom_point(alpha = 0.001) +
#   ggtitle('Average migration content per article across time')


dta_q <- dta %>% 
  dplyr::select(mig_pred, mig_proba, paper, date) %>% 
  filter((lubridate::ym('2020-01') > date & (date > lubridate::ym('2013-01')))) %>%
  mutate(quarter = lubridate::floor_date(date, 'quarter')) %>% 
  group_by(quarter, paper) %>% 
  summarise(
    mig_pred = mean(mig_pred),
    mig_proba = mean(mig_proba)
  )

dta_q %>% 
  ggplot(aes(x = quarter, y = paper, fill = mig_proba)) +
  geom_tile() +
  ggtitle("Estimated probability that a given article is about migration")

dta_q %>% 
  ggplot(aes(x = quarter, y = paper, fill = mig_pred)) +
  geom_tile() +
  ggtitle("Estimated share of migration-related articles")

dta_q %>% 
  ggplot(aes(x = quarter, y = mig_pred)) +
  geom_line() +
  facet_wrap(~paper, nrow = 2) +
  ggtitle("Estimated share of migration-related articles")


```




## preliminary VAR

```{r rrpviol, include = F}

# load and prepare rr violence data
# rwt <- fread(here('_dt/rwt/_rr.csv')) %>% 
#   select(iyear, imonth, iday, success, attacktype1_txt, nkill, nwound, property) %>% 
#   mutate(date = as.IDate(paste(iday, imonth, iyear, sep = '.'), format = '%d.%m.%Y'))


load(here('_dt/_out/_daily.Rdata' ))

w <- w %>% 
  mutate(date = date2,
         paper = source)


# aggregate news data
dta_d <- dta %>% 
  group_by(paper, date) %>% 
  summarise(
    avg_pred = mean(mig_pred),
    avg_proba = mean(mig_proba)
  )

dta_d$paper[dta_d$paper == "weltonline"] <- "welt"


# merge and delete old data
dta_m <- merge(w, dta_d, by = c('date', 'paper'))
rm(dta, dta_d,  dta_q, w)

```

### Test for stationary

```{r adftest}

adf.test(dta_m$natt, k = 14)
adf.test(dta_m$avg_pred, k = 14)


```

Both the number of attacks and the share of migration content are stationary time series.

### Cumulative

```{r var}


# code not properly adapted yet

Y <- 'avg_pred'
C <- 'natt'

# estimate 
for( i in unique(dta_m$paper)){
  t <- dta_m %>% filter( paper == i )
  s <- vars::VARselect( cbind( t[ , Y ], t[ , C ] ) , type = 'both' )
  
  m <- vars::VAR( y = cbind( Y = t[ , Y ], C = t[ , C ])
           , p = s$selection[ 1 ] , type = 'both' )

  p1 <- vars::irf( x = m , impulse = 'C' , response = 'Y' , n.ahead = 14 , cumulative = T )
  
  p1.1 <- cbind( unlist( p1$irf ) , unlist( p1$Lower ) , unlist( p1$Upper )) %>% as.data.frame( ) %>%
    mutate( time = seq_along( V1 ) , mod = paste( i , 'C = Att; Y=Immigr.' , sep = ' - ' ) )
  
  
  library( ggplot2 )
  p <- p1.1 %>%
    ggplot( aes( time , V1 )) +
    geom_point( ) +
    geom_errorbar( aes( ymin = V2 , ymax = V3 ) , width = 0 ) +
    geom_hline( aes( yintercept = 0 ) , linetype = 2 ) +
    facet_wrap( ~mod )
  print( p )
  
}

```

### direct IRF

```{r var_dir}


# code not properly adapted yet

Y <- 'avg_pred'
C <- 'natt'

# estimate 
for( i in unique(dta_m$paper)){
  t <- dta_m %>% filter( paper == i )
  s <- vars::VARselect( cbind( t[ , Y ], t[ , C ] ) , type = 'both' )
  
  m <- vars::VAR( y = cbind( Y = t[ , Y ], C = t[ , C ])
           , p = s$selection[ 1 ] , type = 'both' )

  p1 <- vars::irf( x = m , impulse = 'C' , response = 'Y' , n.ahead = 14 , cumulative = F )
  
  p1.1 <- cbind( unlist( p1$irf ) , unlist( p1$Lower ) , unlist( p1$Upper )) %>% as.data.frame( ) %>%
    mutate( time = seq_along( V1 ) , mod = paste( i , 'C = Att; Y=Immigr.' , sep = ' - ' ) )
  
  
  library( ggplot2 )
  p <- p1.1 %>%
    ggplot( aes( time , V1 )) +
    geom_point( ) +
    geom_errorbar( aes( ymin = V2 , ymax = V3 ) , width = 0 ) +
    geom_hline( aes( yintercept = 0 ) , linetype = 2 ) +
    facet_wrap( ~mod )
  print( p )
  
}

```

### split-sample time (cumulative)

```{r var_split}


for (pre in c(T,F)){
  
  # estimate 
  for( i in unique(dta_m$paper)){
      t <- dta_m %>% filter( paper == i )
      if (pre){
        t <- t %>% filter( date < ym("201601") )
        samplename <- ", up to Jan 2016"
      }else{
        t <- t %>% filter( date >= ym("201601") )
        samplename <- ", since Jan 2016"
      }
      s <- vars::VARselect( cbind( t[ , Y ], t[ , C ] ) , type = 'both' )
      
      m <- vars::VAR( y = cbind( Y = t[ , Y ], C = t[ , C ])
               , p = s$selection[ 1 ] , type = 'both' )
    
      p1 <- vars::irf( x = m , impulse = 'C' , response = 'Y' , n.ahead = 14 , cumulative = T )
      
      p1.1 <- cbind( unlist( p1$irf ) , unlist( p1$Lower ) , unlist( p1$Upper )) %>% as.data.frame( ) %>%
        mutate( time = seq_along( V1 ) , mod = paste( i , 'C = Att; Y=Immigr.', samplename , sep = ' - ' ) )
      
      
      library( ggplot2 )
      p <- p1.1 %>%
        ggplot( aes( time , V1 )) +
        geom_point( ) +
        geom_errorbar( aes( ymin = V2 , ymax = V3 ) , width = 0 ) +
        geom_hline( aes( yintercept = 0 ) , linetype = 2 ) +
        facet_wrap( ~mod )
      print( p )
      
    }
}


```

## preliminary analysis of migration slant

```{r slant_desc}
# rmeove old data, load migration estimates
rm(list = ls())
dta <- fread(here("_dt/_out/_migration_slant_new.csv"))


# clean
dta$paper[dta$paper == "weltonline"] <- "welt"
dta$date_new <- NA_Date_
dta$date_new[dta$paper == "bild"] <- dta$date[dta$paper == "bild"] %>% as.Date()
dta$date_new[dta$paper == "faz"] <- dta$date[dta$paper=="faz"] %>% as.integer() %>% lubridate::days() + as.Date("1970-01-01")
dta$date_new[dta$paper == "spon"] <- dta$date[dta$paper=="spon"] %>% as.Date(format = "%d.%m.%Y")
dta$date_new[dta$paper == "sz"] <- dta$date[dta$paper=="sz"] %>% as.integer() %>% lubridate::days() + as.Date("1970-01-01")
dta$date_new[dta$paper == "taz"] <- dta$date[dta$paper=="taz"] %>% as.integer() %>% lubridate::days() + as.Date("1970-01-01")
dta$date_new[dta$paper == "welt"] <- dta$date[dta$paper=="welt"] %>% as.integer() %>% lubridate::days() + as.Date("1970-01-01")

# aggregate news data (quarter)
dta$quart <- lubridate::floor_date(dta$date_new, unit = 'quarter')
dta_d <- dta %>% 
  filter(paper != "paper") %>% 
  group_by(paper, quart) %>% 
  summarise(
    slant = mean(proba),
    slant_sd = sd(proba),
    n_articles = n()
  )




# plot migration slant of newspapers

## calculate SEs for CIs
dta_d$slant_se = dta_d$slant_sd/sqrt(dta_d$n_articles)
dta_d$low_ci <- dta_d$slant - qt(1 - (0.05 / 2), dta_d$n_articles-1) * dta_d$slant_se
dta_d$upp_ci <- dta_d$slant + qt(1 - (0.05 / 2), dta_d$n_articles-1) * dta_d$slant_se

dta_d %>% 
  filter(quart > as.Date('2013-01-01')) %>% 
  ggplot(aes(x = quart, y = slant, 
             fill = paper, col = paper, group = paper, 
             ymin = low_ci, ymax = upp_ci
             )) + 
  geom_line() +
  geom_ribbon(alpha = 0.5) +
  ggtitle('News slant on migration across time')+
  ylab('Similarity to AfD-framing') + 
  facet_wrap(~paper) +
  theme(legend.position = "none")
```





```{r df_slant}
# aggregate news data (daily)
dta_d <- dta %>% 
  filter(paper != "paper") %>% 
  group_by(paper, date_new) %>% 
  summarise(
    slant = mean(proba),
    slant_sd = sd(proba),
    n_articles = n()
  ) %>% 
  ungroup()


# load rwt data
load(here('_dt/_out/_daily.Rdata' ))

w <- w %>% 
  mutate(date_new = date2,
         paper = source)



# merge and delete old data
dta_m <- merge(w, dta_d, by = c('date_new', 'paper'))
rm(dta, w)

adf.test(dta_m$natt, k = 14)
adf.test(dta_m$slant, k = 14)

```



```{r slant_var}
# VAR

Y <- 'slant'
C <- 'natt'

# estimate 
for( i in unique(dta_m$paper)){
  t <- dta_m %>% filter( paper == i )
  s <- vars::VARselect( cbind( t[ , Y ], t[ , C ] ) , type = 'both' )
  
  m <- vars::VAR( y = cbind( Y = t[ , Y ], C = t[ , C ])
           , p = s$selection[ 1 ] , type = 'both' )

  p1 <- vars::irf( x = m , impulse = 'C' , response = 'Y' , n.ahead = 14 , cumulative = T )
  
  p1.1 <- cbind( unlist( p1$irf ) , unlist( p1$Lower ) , unlist( p1$Upper )) %>% as.data.frame( ) %>%
    mutate( time = seq_along( V1 ) , mod = paste( i , 'C = Att; Y=Migration Slant (higher = more similar to AfD)' , sep = ' - ' ) )
  
  
  library( ggplot2 )
  p <- p1.1 %>%
    ggplot( aes( time , V1 )) +
    geom_point( ) +
    geom_errorbar( aes( ymin = V2 , ymax = V3 ) , width = 0 ) +
    geom_hline( aes( yintercept = 0 ) , linetype = 2 ) +
    facet_wrap( ~mod )
  print( p )
  
}

```

