---
title: "Exploration media reactions"
author: "Nicolai Berk"
date: "28 6 2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, warning = F, message = F, cache = T)

library(here)
library(tidyverse)
library(data.table)
library(glue)
library(lubridate)
library(vars)
library(dplyr)
library(tseries)

```

## Supervised estimates of newspaper articles

This document will explore the estimates of newspaper articles generated by a supervised model. For each article, a buest guess (True/False) of whether the article is about immigration was produced, together with a probability of how likely the article is about immigration. This gives both a binary and a continuous dependent. 


```{r merge, include = F}

filelist <- list.files(here('_dt/_mig_estimates'))


rm(dta)
for (filename in filelist){
  if (!exists('dta')){
    dta <- fread(paste0(here('_dt/_mig_estimates'), '/', filename))
    
    # drop topic (incorrectly assigned, might rerun later)
    dta <- dta[, - c('topic')]
    
  }else{
    
    temp <-  fread(paste0(here('_dt/_mig_estimates'), '/', filename))
    
    # adjust date format if necessary
    if (class(temp$date)[1] == 'integer'){
      temp$date <- as.IDate(temp$date)
    }else if (class(temp$date)[1] == 'character'){
      temp$date <- as.IDate(temp$date, format = '%d.%m.%Y')
    }else if (class(temp$date)[1] == 'IDate'){
      # no need to change
    }else{
      stop(glue('Unclear how to transform class {class(temp$date)[1]} to IDate.'))
    }
    
    temp <- temp[, - c('topic')]
    
    dta <- rbind(dta, temp)
    
    
  }

  # clean journal names
  dta$paper <-  dta$paper %>% 
    gsub(pattern = '_articles.csv', replacement = '') %>%
    gsub(pattern = '_', replacement = '')
  
}

rm(temp)



```



## Summary statistics

### overview of dataset

```{r summary}
summary(dta)
```

### Share of positives and histogram of probability

```{r hist}
print(paste('Share of migration articles:', round(sum(dta$mig_pred)/nrow(dta), 2)))

round(prop.table(table(dta$paper, dta$mig_pred), margin = 1), 2)

hist(dta$mig_proba, main = "Estimated probability an article is about migration")



```

## articles over time

```{r overtime}
dta %>% 
  filter(mig_pred == 1 & (date > lubridate::ym('2013-01'))) %>%
  ggplot() +
  ggridges::geom_density_ridges(aes(x = date, y = paper)) +
  ggtitle('Distribution of migration-related articles')

dta %>% 
  filter((date > lubridate::ym('2013-01'))) %>%
  ggplot() +
  ggridges::geom_density_ridges(aes(x = date, y = paper)) +
  ggtitle('Distribution of all articles')



# dta %>% 
#   filter((date > lubridate::ym('2013-01'))) %>%
#   ggplot(aes(x = date, y = mig_proba)) +
#   geom_smooth(aes(col = paper)) +
#   geom_point(alpha = 0.001) +
#   ggtitle('Average migration content per article across time')


dta_q <- dta %>% 
  dplyr::select(mig_pred, mig_proba, paper, date) %>% 
  filter((lubridate::ym('2020-01') > date & (date > lubridate::ym('2013-01')))) %>%
  mutate(quarter = lubridate::floor_date(date, 'quarter')) %>% 
  group_by(quarter, paper) %>% 
  summarise(
    mig_pred = mean(mig_pred),
    mig_proba = mean(mig_proba)
  )

dta_q %>% 
  ggplot(aes(x = quarter, y = paper, fill = mig_proba)) +
  geom_tile() +
  ggtitle("Estimated probability that a given article is about migration")

dta_q %>% 
  ggplot(aes(x = quarter, y = paper, fill = mig_pred)) +
  geom_tile() +
  ggtitle("Estimated share of migration-related articles")

dta_q %>% 
  ggplot(aes(x = quarter, y = mig_pred)) +
  geom_line() +
  facet_wrap(~paper, nrow = 2) +
  ggtitle("Estimated share of migration-related articles")


```




## preliminary VAR

```{r rrpviol, include = F}

# load and prepare rr violence data
# rwt <- fread(here('_dt/rwt/_rr.csv')) %>% 
#   select(iyear, imonth, iday, success, attacktype1_txt, nkill, nwound, property) %>% 
#   mutate(date = as.IDate(paste(iday, imonth, iyear, sep = '.'), format = '%d.%m.%Y'))


load(here('_dt/_out/_daily.Rdata' ))

w <- w %>% 
  mutate(date = date2,
         paper = source)


# aggregate news data
dta_d <- dta %>% 
  group_by(paper, date) %>% 
  summarise(
    avg_pred = mean(mig_pred),
    avg_proba = mean(mig_proba)
  )

dta_d$paper[dta_d$paper == "weltonline"] <- "welt"


# merge and delete old data
dta_m <- merge(w, dta_d, by = c('date', 'paper'))
rm(dta, dta_d,  dta_q, w)

```

### Test for stationary

```{r adftest}

adf.test(dta_m$natt, k = 14)
adf.test(dta_m$avg_pred, k = 14)


```

Both the number of attacks and the share of migration content are stationary time series.

### Cumulative

```{r var}


# code not properly adapted yet

Y <- 'avg_pred'
C <- 'natt'

# estimate 
for( i in unique(dta_m$paper)){
  t <- dta_m %>% filter( paper == i )
  s <- vars::VARselect( cbind( t[ , Y ], t[ , C ] ) , type = 'both' )
  
  m <- vars::VAR( y = cbind( Y = t[ , Y ], C = t[ , C ])
           , p = s$selection[ 1 ] , type = 'both' )

  p1 <- vars::irf( x = m , impulse = 'C' , response = 'Y' , n.ahead = 14 , cumulative = T )
  
  p1.1 <- cbind( unlist( p1$irf ) , unlist( p1$Lower ) , unlist( p1$Upper )) %>% as.data.frame( ) %>%
    mutate( time = seq_along( V1 ) , mod = paste( i , 'C = Att; Y=Immigr.' , sep = ' - ' ) )
  
  
  library( ggplot2 )
  p <- p1.1 %>%
    ggplot( aes( time , V1 )) +
    geom_point( ) +
    geom_errorbar( aes( ymin = V2 , ymax = V3 ) , width = 0 ) +
    geom_hline( aes( yintercept = 0 ) , linetype = 2 ) +
    facet_wrap( ~mod )
  print( p )
  
}

```

### direct IRF

```{r var_dir}


# code not properly adapted yet

Y <- 'avg_pred'
C <- 'natt'

# estimate 
for( i in unique(dta_m$paper)){
  t <- dta_m %>% filter( paper == i )
  s <- vars::VARselect( cbind( t[ , Y ], t[ , C ] ) , type = 'both' )
  
  m <- vars::VAR( y = cbind( Y = t[ , Y ], C = t[ , C ])
           , p = s$selection[ 1 ] , type = 'both' )

  p1 <- vars::irf( x = m , impulse = 'C' , response = 'Y' , n.ahead = 14 , cumulative = F )
  
  p1.1 <- cbind( unlist( p1$irf ) , unlist( p1$Lower ) , unlist( p1$Upper )) %>% as.data.frame( ) %>%
    mutate( time = seq_along( V1 ) , mod = paste( i , 'C = Att; Y=Immigr.' , sep = ' - ' ) )
  
  
  library( ggplot2 )
  p <- p1.1 %>%
    ggplot( aes( time , V1 )) +
    geom_point( ) +
    geom_errorbar( aes( ymin = V2 , ymax = V3 ) , width = 0 ) +
    geom_hline( aes( yintercept = 0 ) , linetype = 2 ) +
    facet_wrap( ~mod )
  print( p )
  
}

```

### split-sample time (cumulative)

```{r var_split}


for (pre in c(T,F)){
  
  # estimate 
  for( i in unique(dta_m$paper)){
      t <- dta_m %>% filter( paper == i )
      if (pre){
        t <- t %>% filter( date < ym("201601") )
        samplename <- ", up to Jan 2016"
      }else{
        t <- t %>% filter( date >= ym("201601") )
        samplename <- ", since Jan 2016"
      }
      s <- vars::VARselect( cbind( t[ , Y ], t[ , C ] ) , type = 'both' )
      
      m <- vars::VAR( y = cbind( Y = t[ , Y ], C = t[ , C ])
               , p = s$selection[ 1 ] , type = 'both' )
    
      p1 <- vars::irf( x = m , impulse = 'C' , response = 'Y' , n.ahead = 14 , cumulative = T )
      
      p1.1 <- cbind( unlist( p1$irf ) , unlist( p1$Lower ) , unlist( p1$Upper )) %>% as.data.frame( ) %>%
        mutate( time = seq_along( V1 ) , mod = paste( i , 'C = Att; Y=Immigr.', samplename , sep = ' - ' ) )
      
      
      library( ggplot2 )
      p <- p1.1 %>%
        ggplot( aes( time , V1 )) +
        geom_point( ) +
        geom_errorbar( aes( ymin = V2 , ymax = V3 ) , width = 0 ) +
        geom_hline( aes( yintercept = 0 ) , linetype = 2 ) +
        facet_wrap( ~mod )
      print( p )
      
    }
}


```

## preliminary analysis of migration slant

```{r slant}

# rmeove old data, load migration estimates
rm(list = ls())
dta <- fread(here("_dt/_out/_migration_slant.csv"))

# aggregate news data
dta_d <- dta %>% 
  filter(paper != "paper") %>% 
  group_by(paper, date) %>% 
  summarise(
    slant = mean(proba)
  )


# clean
dta_d$paper[dta_d$paper == "weltonline"] <- "welt"
dta_d$date_new <- NA_Date_
dta_d$date_new[dta_d$paper == "bild"] <- dta_d$date[dta_d$paper == "bild"] %>% as.Date()
dta_d$date_new[dta_d$paper == "faz"] <- dta_d$date[dta_d$paper=="faz"] %>% as.integer() %>% lubridate::days() + as.Date("1970-01-01")
dta_d$date_new[dta_d$paper == "spon"] <- dta_d$date[dta_d$paper=="spon"] %>% as.Date(format = "%d.%m.%Y")
dta_d$date_new[dta_d$paper == "sz"] <- dta_d$date[dta_d$paper=="sz"] %>% as.integer() %>% lubridate::days() + as.Date("1970-01-01")
dta_d$date_new[dta_d$paper == "taz"] <- dta_d$date[dta_d$paper=="taz"] %>% as.integer() %>% lubridate::days() + as.Date("1970-01-01")
dta_d$date_new[dta_d$paper == "welt"] <- dta_d$date[dta_d$paper=="welt"] %>% as.integer() %>% lubridate::days() + as.Date("1970-01-01")


# load rwt data
load(here('_dt/_out/_daily.Rdata' ))

w <- w %>% 
  mutate(date_new = date2,
         paper = source)



# merge and delete old data
dta_m <- merge(w, dta_d, by = c('date_new', 'paper'))
rm(dta, w)


# VAR

Y <- 'slant'
C <- 'natt'

# estimate 
for( i in unique(dta_m$paper)){
  t <- dta_m %>% filter( paper == i )
  s <- vars::VARselect( cbind( t[ , Y ], t[ , C ] ) , type = 'both' )
  
  m <- vars::VAR( y = cbind( Y = t[ , Y ], C = t[ , C ])
           , p = s$selection[ 1 ] , type = 'both' )

  p1 <- vars::irf( x = m , impulse = 'C' , response = 'Y' , n.ahead = 14 , cumulative = T )
  
  p1.1 <- cbind( unlist( p1$irf ) , unlist( p1$Lower ) , unlist( p1$Upper )) %>% as.data.frame( ) %>%
    mutate( time = seq_along( V1 ) , mod = paste( i , 'C = Att; Y=Migration Slant (higher = more similar to AfD)' , sep = ' - ' ) )
  
  
  library( ggplot2 )
  p <- p1.1 %>%
    ggplot( aes( time , V1 )) +
    geom_point( ) +
    geom_errorbar( aes( ymin = V2 , ymax = V3 ) , width = 0 ) +
    geom_hline( aes( yintercept = 0 ) , linetype = 2 ) +
    facet_wrap( ~mod )
  print( p )
  
}

```

